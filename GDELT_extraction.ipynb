{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c66d27f-09d4-46b3-a4bc-cae9f70d966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812ef54-d197-4157-b740-9f1a26be8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = \"filtered_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Base URL for GDELT event data\n",
    "gdelt_base_url = \"http://data.gdeltproject.org/events/\"\n",
    "\n",
    "# Define date range\n",
    "start_year, start_month = 2016, 1\n",
    "end_year, end_month = 2020, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20422bf-905f-4703-846a-2ab4b3d5701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls():\n",
    "    urls = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            if year == end_year and month > end_month:\n",
    "                break\n",
    "            for day in range(1, 32):  # Adding day to the date string\n",
    "                date_str = f\"{year}{month:02d}{day:02d}\"\n",
    "                url = f\"{gdelt_base_url}{date_str}.export.CSV.zip\"\n",
    "                urls.append((date_str[:6], url))  # Return YYYYMM as key\n",
    "    return urls\n",
    "\n",
    "urls = generate_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358a54b-08b6-4ebc-87d8-a8ce5d65ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {\n",
    "    \"FractionDate\": float,\n",
    "    \"GoldsteinScale\": float,\n",
    "    \"NumMentions\": float,\n",
    "    \"NumSources\": float,\n",
    "    \"NumArticles\": float,\n",
    "    \"AvgTone\": float,\n",
    "    \"Actor1Geo_Lat\": float,\n",
    "    \"Actor1Geo_Long\": float,\n",
    "    \"Actor2Geo_Lat\": float,\n",
    "    \"Actor2Geo_Long\": float,\n",
    "    \"ActionGeo_Lat\": float,\n",
    "    \"ActionGeo_Long\": float,\n",
    "}\n",
    "\n",
    "\n",
    "italy_code = 'ITA'\n",
    "china_code = 'CHN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35036e-9125-405f-ab6a-1d5f404fb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_filter():\n",
    "    monthly_data = defaultdict(list)\n",
    "    column_names = [\n",
    "        \"GlobalEventID\", \"SQLDATE\", \"MonthYear\", \"Year\", \"FractionDate\", \"Actor1Code\", \"Actor1Name\", \"Actor1CountryCode\", \n",
    "        \"Actor1KnownGroupCode\", \"Actor1EthnicCode\", \"Actor1Religion1Code\", \"Actor1Religion2Code\", \"Actor1Type1Code\", \n",
    "        \"Actor1Type2Code\", \"Actor1Type3Code\", \"Actor2Code\", \"Actor2Name\", \"Actor2CountryCode\", \"Actor2KnownGroupCode\", \n",
    "        \"Actor2EthnicCode\", \"Actor2Religion1Code\", \"Actor2Religion2Code\", \"Actor2Type1Code\", \"Actor2Type2Code\", \"Actor2Type3Code\", \n",
    "        \"IsRootEvent\", \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \"NumMentions\", \n",
    "        \"NumSources\", \"NumArticles\", \"AvgTone\", \"Actor1Geo_Type\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryCode\", \n",
    "        \"Actor1Geo_ADM1Code\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \"Actor1Geo_FeatureID\", \"Actor2Geo_Type\", \n",
    "        \"Actor2Geo_FullName\", \"Actor2Geo_CountryCode\", \"Actor2Geo_ADM1Code\", \"Actor2Geo_Lat\", \"Actor2Geo_Long\", \n",
    "        \"Actor2Geo_FeatureID\", \"ActionGeo_Type\", \"ActionGeo_FullName\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "        \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \"DATEADDED\", \"SOURCEURL\"\n",
    "    ]\n",
    "    \n",
    "    # Define the country codes for Italy and China\n",
    "    italy_code = 'ITA'\n",
    "    china_code = 'CHN'\n",
    "\n",
    "    # Loop over the (month, url) pairs\n",
    "    for month, url in urls:\n",
    "        output_file = os.path.join(output_dir, f\"filtered_{month}.csv\")\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {url} for {month}, already processed.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Downloading {url} for month {month}\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "                for filename in z.namelist():\n",
    "                    with z.open(filename) as file:\n",
    "                        # Read the data file with proper settings\n",
    "                        df = pd.read_csv(file, sep='\\t', header=None, encoding='latin1', low_memory=False, dtype=str)\n",
    "                        df.columns = column_names  # Assign column names\n",
    "\n",
    "                        # Filter rows: keep only those where one actor is from CHN and the other from ITA\n",
    "                        df_filtered = df[\n",
    "                            ((df['Actor1CountryCode'] == china_code) & (df['Actor2CountryCode'] == italy_code)) |\n",
    "                            ((df['Actor1CountryCode'] == italy_code) & (df['Actor2CountryCode'] == china_code))\n",
    "                        ]\n",
    "\n",
    "                        # Convert numeric columns to floats where possible\n",
    "                        numeric_cols = [\n",
    "                            \"FractionDate\", \"GoldsteinScale\", \"NumMentions\", \"NumSources\", \n",
    "                            \"NumArticles\", \"AvgTone\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \n",
    "                            \"Actor2Geo_Lat\", \"Actor2Geo_Long\", \"ActionGeo_Lat\", \"ActionGeo_Long\"\n",
    "                        ]\n",
    "                        for col in numeric_cols:\n",
    "                            if col in df_filtered.columns:\n",
    "                                df_filtered[col] = pd.to_numeric(df_filtered[col], errors='coerce')\n",
    "                        \n",
    "                        monthly_data[month].append(df_filtered)\n",
    "        else:\n",
    "            print(f\"Failed to download {url}\")\n",
    "\n",
    "    # Save one file per month by combining all corresponding dataframes\n",
    "    for month, dataframes in monthly_data.items():\n",
    "        if dataframes:\n",
    "            df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "            output_file = os.path.join(output_dir, f\"filtered_{month}.csv\")\n",
    "            df_combined.to_csv(output_file, index=False, sep='\\t')\n",
    "            print(f\"Saved {output_file} with {len(df_combined)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd446a1-901d-45a3-9975-d251025d443f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process all URLs\n",
    "for url in urls:\n",
    "    print(url)\n",
    "    download_and_filter()\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8589bc-4bc9-4c06-9512-a9f23738bac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be331587-5765-408a-96dd-4766f6246b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
